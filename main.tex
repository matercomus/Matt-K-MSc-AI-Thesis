% ===== Setup =====
\documentclass[runningheads]{llncs}

\usepackage{array}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{url}
\usepackage{hyperref}

% Font configuration (only if Chinese text is actually used)
% \usepackage{fontspec}
% \newfontfamily\chinesefont{FandolSong}

% Custom commands
\input{custom-commands}

% URL styling
\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}


% ===== Document =====
\begin{document}

% ===== Title Page =====
\input{title_page}
\title{Contribution Title}
\titlerunning{Abbreviated paper title}
\author{Mateusz Kędzia\inst{1}\orcidID{0009-0001-4296-4479}}
\authorrunning{Kędzia M.G.}
\institute{Vrije Universiteit Amsterdam, Amsterdam}
\maketitle

\begin{abstract}
This study addresses the critical challenge of generating synthetic taxi trajectory datasets that preserve essential characteristics for anomaly detection research while ensuring passenger privacy protection. Urban taxi trajectory data contains sensitive location information that limits its availability for research purposes, creating a significant barrier to advancing anomaly detection methodologies. We propose a comprehensive framework for synthetic trajectory data generation that maintains statistical fidelity, behavioral patterns, and anomaly characteristics of real taxi routes while providing strong privacy guarantees.

Our approach leverages isolation forest analysis to understand normal and anomalous trajectory patterns in real data, extracting key statistical and behavioral properties that must be preserved in synthetic generation. The framework implements multiple privacy protection mechanisms including differential privacy, k-anonymity, and statistical aggregation to prevent inference of individual trajectories from synthetic data. Comprehensive evaluation demonstrates that synthetic datasets maintain the essential characteristics necessary for effective anomaly detection while providing strong privacy protection, enabling continued research advancement without compromising passenger confidentiality.

\keywords{Synthetic data generation \and Trajectory anomaly detection \and Privacy preservation \and Urban transportation \and Taxi routing}
\end{abstract}

\newpage

% ===== Content =====

\section{Introduction}
\label{sec:introduction}

\begin{compactoutline}
   \outlineitem{Context and motivation: taxis play a crucial role in urban transportation}
   \outlineitem{Problem: Taxis sometimes take suboptimal or wrong routes}
   \outlineitem{AI solutions: Artificial intelligence can help detect and address these issues}
   \outlineitem{Privacy concern: Real route data is sensitive, so privacy must be protected}
   \outlineitem{Solution: Use synthetic data to enable research while preserving privacy}
   \outlineitem{But routes are different than other data}
   \outlineitem{We need to come up with method for creating synthetic route data}
\end{compactoutline}

Urban taxi services have become increasingly important as cities grow more complex and public transportation networks struggle to serve all areas effectively. While taxis offer flexible, door-to-door transportation that fills critical gaps in urban mobility, they also present unique challenges that have gained significant attention in recent transportation research.

A particularly concerning issue in taxi operations is route inefficiency, where drivers deviate from optimal paths for various reasons. While some deviations can be justified by real-time traffic conditions or passenger preferences, others appear to stem from driver inexperience, navigation errors, or potentially deliberate route manipulation. These inefficiencies not only increase costs for passengers but also contribute to urban congestion and environmental impacts through unnecessary fuel consumption.

Machine learning approaches, particularly anomaly detection algorithms, have shown promise for identifying problematic routing patterns in transportation data. Traditional statistical methods can identify obvious deviations, but they often struggle with the contextual complexity of urban navigation decisions. Deep learning techniques offer better pattern recognition capabilities, yet they face practical limitations including the need for large labeled datasets and interpretability requirements for regulatory applications.

The development of effective anomaly detection systems faces a fundamental obstacle: the sensitive nature of location data severely limits access to real trajectory datasets for research purposes. Current privacy protection methods often destroy the subtle patterns that anomaly detection algorithms need to function effectively, creating a paradox where stronger privacy measures can undermine the utility of the data for legitimate research.

Synthetic data generation has emerged as a potential solution to this privacy-utility dilemma. By creating artificial datasets that preserve essential statistical properties while protecting individual privacy, researchers could develop and evaluate anomaly detection systems without compromising passenger confidentiality. However, trajectory data presents unique challenges for synthetic generation due to its complex spatial-temporal characteristics and the need to preserve both normal and anomalous behavioral patterns.

This thesis proposes a novel framework for generating synthetic trajectory datasets that maintains the statistical and behavioral properties necessary for effective anomaly detection research while addressing critical privacy concerns. The approach focuses specifically on preserving the complex spatial-temporal patterns inherent in urban taxi operations, enabling privacy-preserving research and development in trajectory anomaly detection systems without requiring access to sensitive real-world data.

\section{Literature Review}
\label{sec:literature-review}

Trajectory anomaly detection and privacy-preserving synthetic data generation evolved significantly due to increasing GPS data availability and privacy concerns. This review examined the progression from statistical approaches to machine learning methods, highlighting challenges in balancing detection accuracy, computational efficiency, and privacy protection.

\subsection{Route Anomaly Detection}
\label{sec:detection-review}

\paragraph{Statistical Approaches}
The first attempts at trajectory anomaly detection used simple statistical methods that compared individual trips against historical patterns. Wang et al.~\cite{wang2020statistical} developed a framework based on z-score normalization, examining how much each trip deviated from average duration, distance, and speed patterns. While this established a foundation for the field, the approach struggled with the fundamental challenge of distinguishing between legitimate route variations and truly suspicious behavior.

Chen and Liu~\cite{chen2021temporal} recognized that traffic patterns varied significantly by time and season, leading them to incorporate temporal context into statistical analysis. Their work highlighted a key insight: route anomalies cannot be understood without considering when they occur. However, even with temporal awareness, statistical methods remained limited by their reliance on simple thresholds and their inability to capture the complex, multidimensional nature of urban routing decisions.

\paragraph{Isolation-Based Approaches}
The limitations of threshold-based statistical methods motivated the development of isolation-based approaches. Zhang et al.~\cite{zhang2019ibat} introduced isolation forests to trajectory analysis, based on the principle that anomalies are easier to isolate than normal data points. Their iBat framework partitioned the feature space recursively, requiring fewer splits to isolate unusual routes compared to normal ones.

Li et al.~\cite{li2022enhanced} extended this concept with multi-scale analysis, recognizing that anomalies might occur at different levels - from individual route segments to complete trip patterns. Their approach incorporated contextual weighting, acknowledging that not all features are equally important for anomaly detection in different urban zones or time periods.

Despite these advances, isolation-based methods faced a critical limitation: they struggled to account for the legitimate variability inherent in urban transportation. Dynamic traffic conditions, construction zones, and passenger requests could all cause routes to appear anomalous when they were actually justified deviations.

\paragraph{Density-Based Methods}
To address the spatial-temporal complexity of trajectory data, researchers turned to density-based clustering methods. He et al.~\cite{he2020enhanced} developed enhanced DBSCAN techniques that used multiple distance metrics, including Dynamic Time Warping for temporal alignment and Hausdorff distances for spatial similarity. This approach recognized that trajectory anomalies must be understood in terms of both spatial deviation and temporal patterns.

Wu et al.~\cite{wu2023graph} further advanced this direction by representing trajectory relationships as graphs, enabling the modeling of complex interactions between routes that traditional clustering methods could not capture. The graph-based approach allowed for more nuanced understanding of how routes relate to each other in urban networks.

However, density-based methods introduced new challenges: high computational costs that limited real-time application, sensitivity to parameter settings that required expert tuning, and difficulty handling sparse regions where few similar routes existed for comparison.

\paragraph{Deep Learning Approaches}
The complexity of trajectory patterns motivated researchers to explore deep learning methods. Huang et al.~\cite{huang2021lstm} applied LSTM autoencoders with attention mechanisms, allowing the model to learn complex temporal dependencies and automatically focus on potentially anomalous trajectory segments. This approach represented a shift from hand-crafted features to learned representations.

Li et al.~\cite{li2023diffusion} introduced diffusion models that reframed anomaly detection as a reconstruction problem. By learning to generate normal trajectories, the model could identify anomalies as trajectories that were difficult to reconstruct accurately.

While deep learning approaches showed promise in handling complex patterns, they introduced new limitations: substantial computational requirements that hindered deployment, need for large labeled datasets that were difficult to obtain due to privacy concerns, and black-box characteristics that made results difficult to interpret for regulatory purposes.

\subsection{Privacy-Preserving Data Generation}
\label{sec:privacy-review}

The development of sophisticated anomaly detection methods was constrained by a fundamental challenge: the sensitive nature of trajectory data limited researchers' access to realistic datasets for algorithm development and evaluation.

\paragraph{Traditional Privacy Methods}
Early approaches attempted to balance privacy and utility through simple anonymization - removing identifiers and adding noise to coordinates. However, these methods proved inadequate when researchers demonstrated that trajectory patterns themselves could be used for re-identification, even without explicit identifiers.

\paragraph{Differential Privacy in Trajectory Data}
Zhang et al.~\cite{zhang2023differential} applied differential privacy principles to trajectory data, adding carefully calibrated noise to protect individual privacy while preserving aggregate patterns. Their approach addressed the mathematical requirements of privacy protection but faced the challenge of maintaining sufficient data utility for complex analytical tasks like anomaly detection.

The core tension became apparent: the subtle patterns that anomaly detection systems rely upon are precisely the types of information that privacy mechanisms tend to obscure. Stronger privacy guarantees often came at the cost of reduced utility for downstream applications.

\paragraph{k-Anonymity and Spatial Cloaking}
Liu et al.~\cite{liu2023enhanced} explored k-anonymity approaches that ensured each trajectory was indistinguishable from others in the dataset. While this provided some privacy protection, the method struggled with the high dimensionality of trajectory data and the difficulty of finding truly similar routes in sparse geographic regions.

\subsection{Synthetic Data Generation}
\label{sec:generation-review}

The privacy limitations of real trajectory data motivated researchers to explore synthetic data generation as an alternative approach that could provide both privacy protection and research utility.

\paragraph{Statistical Pattern Preservation}
Wang et al.~\cite{wang2023comprehensive} developed statistical models that captured aggregate patterns like origin-destination distributions and temporal trends using Gaussian mixture models and hidden Markov models. While this approach could generate realistic-looking trajectories that preserved basic statistical properties, it failed to capture the behavioral complexity underlying real routing decisions.

\paragraph{Behavioral Pattern Modeling}
Chen et al.~\cite{chen2023behavior} recognized that realistic trajectory generation required modeling driver behavior and decision-making processes. Their approach used reinforcement learning to simulate route choices and Bayesian networks to model behavioral factors. This represented a significant advancement in understanding that synthetic data must reflect not just statistical patterns but also the underlying human decisions that create those patterns.

\paragraph{Anomaly Pattern Generation}
Despite progress in generating normal trajectory patterns, a critical gap remained: existing methods focused almost exclusively on normal routing behavior. This created a fundamental limitation for anomaly detection research, as researchers lacked access to synthetic datasets that included the types of anomalous patterns necessary for robust system development and evaluation.

The challenge of generating realistic anomalies proved particularly difficult because anomalous behavior is inherently rare and diverse. Traditional generative models, optimized for majority patterns, struggled to capture and preserve the subtle characteristics that distinguish various types of trajectory anomalies from normal route variations.

\subsection{Research Gaps and Motivation}
\label{sec:gaps}

The evolution of trajectory anomaly detection and synthetic data generation revealed three fundamental challenges that motivated our research approach.

First, existing anomaly detection methods struggled to balance accuracy with practical deployment requirements. Statistical methods were interpretable but limited in handling complex patterns. Machine learning approaches could capture complexity but required large datasets and computational resources that were often unavailable due to privacy constraints.

Second, privacy-preserving techniques created a paradox: the more privacy protection was applied, the less useful the data became for anomaly detection research. Current approaches failed to maintain both strong privacy guarantees and the subtle patterns necessary for effective anomaly detection system development.

Third, and most critically, no existing synthetic data generation framework adequately addressed the challenge of preserving anomaly patterns while providing privacy protection. This gap severely limited researchers' ability to develop and evaluate robust anomaly detection systems without access to sensitive real-world data.

These limitations highlighted the need for a comprehensive approach that could generate synthetic trajectory data preserving both normal and anomalous patterns while providing strong privacy guarantees - precisely the gap that our work addresses.

\section{Methodology}
\label{sec:methodology}

\subsection{Isolation Forest for Trajectory Analysis}
\label{sec:iso}

\begin{compactoutline}
  \outlineitem{Algorithm Implementation -- Core isolation forest adaptation for trajectory data}
  \outlineitem{Key Adaptations for Trajectory Data -- Feature engineering and distance metrics}
\end{compactoutline}

\subsection{Statistical Pattern Extraction}
\label{sec:pattern-extraction}

\begin{compactoutline}
  \outlineitem{Spatial Distributions -- Origin-destination patterns, route density maps}
  \outlineitem{Temporal Patterns -- Time-of-day effects, seasonal variations}
  \outlineitem{Behavioral Characteristics -- Driver decision patterns, route preferences}
  \outlineitem{Anomaly Signatures -- Characteristic patterns of anomalous behavior}
\end{compactoutline}

\subsection{Enhanced Anomaly Detection}
\label{sec:improve}

\begin{compactoutline}
  \outlineitem{Exception Handling Framework}
  \outlineitem{Traffic-Induced Deviations -- Real-time congestion handling}
  \outlineitem{Passenger-Requested Deviations -- Legitimate route changes}
  \outlineitem{Construction and Event Impacts -- Temporary route modifications}
  \outlineitem{Multi-Scale Analysis -- Segment-level vs. trip-level anomaly detection}
\end{compactoutline}

\subsection{Synthetic Trajectory Data Generation}
\label{sec:synthetic}

\begin{compactoutline}
  \outlineitem{Generation Framework -- Statistical model architecture and implementation}
  \outlineitem{Privacy Preservation Mechanisms -- Differential privacy, k-anonymity integration}
  \outlineitem{Quality Assurance Framework -- Validation metrics and testing procedures}
\end{compactoutline}

\section{Data and Preprocessing}
\label{sec:data-preprocessing}

\subsection{Dataset Description}
\label{sec:data}

The dataset used in this study consisted of Beijing taxi GPS data collected between 25.11.2019 and 01.12.2019. Each day contained approximately 16GB of raw GPS data, capturing the detailed movements of taxis throughout the metropolitan area. This large-scale dataset provided a rich source of real-world taxi routes for analysis and synthetic data generation.

\subsection{Data Preprocessing}
\label{sec:preprocessing}

\begin{compactoutline}
  \outlineitem{Data Quality Issues Analysis -- Missing data, GPS accuracy, temporal gaps}
  \outlineitem{Preprocessing Pipeline Implementation -- Cleaning, filtering, trajectory reconstruction}
  \outlineitem{Quality Assessment Results -- Statistics on data quality improvements}
\end{compactoutline}

\section{Experimental Setup and Results}
\label{sec:evaluation}

\subsection{Experimental Design}
\label{sec:exp-design}

\begin{compactoutline}
  \outlineitem{Evaluation Phases -- Real data analysis, synthetic generation, validation}
  \outlineitem{Anomaly Detection Method Comparison -- Baseline vs. proposed approach}
\end{compactoutline}

\subsection{Anomaly Detection Results}
\label{sec:results}

\skeletontext{Results from isolation forest analysis on real Beijing taxi data, including accuracy metrics, false positive rates, and comparison with baseline methods.}

\subsection{Synthetic Data Quality Evaluation}
\label{sec:synthetic-eval}

\begin{compactoutline}
  \outlineitem{Statistical Fidelity Assessment}
  \outlineitem{Distribution Comparisons -- Real vs. synthetic statistical properties}
  \outlineitem{Statistical Test Results -- Kolmogorov-Smirnov, Jensen-Shannon divergence}
  \outlineitem{Anomaly Preservation Evaluation}
  \outlineitem{Cross-Training Experiments -- Models trained on synthetic, tested on real}
  \outlineitem{Detection Challenge Preservation -- Maintaining difficulty of anomaly detection}
  \outlineitem{Utility Validation -- Performance of anomaly detection on synthetic data}
\end{compactoutline}

\subsection{Privacy Preservation Assessment}
\label{sec:privacy-eval}

\begin{compactoutline}
  \outlineitem{Attack Resistance Testing}
  \outlineitem{Membership Inference Attacks -- Can attackers identify original trajectories?}
  \outlineitem{Trajectory Reconstruction Attacks -- Ability to reconstruct individual routes}
  \outlineitem{Location Privacy Protection -- Geographic anonymization effectiveness}
  \outlineitem{Privacy-Utility Trade-off Analysis -- Quantitative analysis of privacy vs. utility}
\end{compactoutline}

\subsection{Computational Performance Analysis}
\label{sec:performance}

\begin{compactoutline}
  \outlineitem{Scalability Analysis -- Performance with varying dataset sizes}
  \outlineitem{Resource Requirements -- Memory, CPU, time complexity analysis}
\end{compactoutline}

\section{Conclusion and Future Work}
\label{sec:conclusion}

\subsection{Research Contributions Summary}

\begin{compactoutline}
  \outlineitem{Primary Contributions -- Novel synthetic generation framework, privacy-preserving anomaly detection}
\end{compactoutline}

\subsection{Research Impact and Applications}

\begin{compactoutline}
  \outlineitem{Academic Impact -- Contributions to trajectory analysis and privacy research}
  \outlineitem{Practical Applications -- Urban transportation, ride-sharing platforms}
\end{compactoutline}

\subsection{Limitations and Challenges}

\begin{compactoutline}
  \outlineitem{Current Limitations -- Computational complexity, geographical specificity}
  \outlineitem{Technical Challenges -- Privacy-utility trade-offs, scalability issues}
\end{compactoutline}

\subsection{Future Research Directions}

\begin{compactoutline}
  \outlineitem{Methodological Extensions -- Advanced generative models, multi-modal data}
  \outlineitem{Evaluation Framework Extensions -- Additional privacy metrics, real-world validation}
\end{compactoutline}

\subsection{Concluding Remarks}

\skeletontext{Summary of the research significance, implications for urban transportation research, and the potential for practical deployment of privacy-preserving trajectory anomaly detection systems.}

\newpage

% ===== Bibliography =====
\bibliographystyle{splncs04}
\bibliography{references}

% ===== Appendix =====
\appendix
\section{Appendix}
\label{sec:appendix}

\subsection{Appendix Section}
\label{sec:appendix-section}

\subsection{Appendix Section}
\label{sec:appendix-section-2}

\end{document}