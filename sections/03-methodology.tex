\section{Methodology}
\label{sec:methodology}

This research addresses the critical convergence point identified in the literature review (Section~\ref{sec:synthesis}) by developing a comprehensive privacy-preserving framework for synthetic trajectory anomaly detection. The methodology directly responds to the fundamental challenge that traditional privacy protection methods destroy the spatio-temporal relationships essential for accurate anomaly detection~\cite{buchholzSystematisationKnowledgeTrajectory2024}, while existing synthetic generation approaches fail to provide adequate privacy guarantees~\cite{liuTrajGANsUsingGenerative2018}.

Building on the identified requirements for pattern preservation under privacy constraints, scalable synthetic generation, and systematic evaluation capabilities, this framework introduces an iterative approach that integrates DiffTraj-based synthetic generation~\cite{zhuDiffTrajGeneratingGPS2023}, LM-TAD anomaly detection~\cite{mbuyaTrajectoryAnomalyDetection2024}, and comprehensive privacy protection mechanisms. The methodology ensures that privacy protection is integrated throughout the entire research pipeline rather than treated as a post-processing step.

The framework is developed and validated using Beijing taxi trajectory data as the primary dataset, with generalizability assessed through independent pipeline execution on additional urban datasets (Chengdu, Xi'an). This per-city approach ensures robust model development while enabling systematic evaluation of framework transferability across diverse urban environments without the complexity of joint multi-city training. Each city dataset maintains independent privacy budgets and model parameters, providing clear evaluation of generalization capabilities.

The framework bootstraps controllable and diverse synthetic anomaly generation without requiring pre-labeled anomaly data, addressing the parameter sensitivity and labeled data scarcity issues identified in anomaly detection research~\cite{zhangIBATDetectingAnomalous2011}. Through iterative refinement combining unsupervised detection, diverse querying based on the SOEL framework~\cite{liDeepAnomalyDetection2023}, and rule-based curation, the methodology enables systematic evaluation of anomaly detection methods while maintaining strong privacy guarantees. The process consists of three main phases designed to enrich the synthetic dataset with specific, interpretable anomalies while preserving privacy by design, as formalized in Algorithms~\ref{alg:iterative-generation} and~\ref{alg:anomaly-mining}.

\begin{algorithm}[h!]
  \caption{Iterative Anomaly Generation Framework}\label{alg:iterative-generation}
  \begin{algorithmic}[1]
    \Require $D_{real}, N, M, LM\text{-}TAD, Rules$
    \Ensure $G_N, D_{anomalous}$

    \State Initialize and train generative model $G_0$ on $D_{real}$.
    \State $D_{enriched} \gets D_{real}$.
    \State $D_{anomalous} \gets \emptyset$.

    \For{$i \gets 1$ to $N$}
    \State $D_{new\_anomalies} \gets \text{MineAnomalies}(G_{i-1}, M, LM\text{-}TAD, Rules)$.
    \State $D_{anomalous} \gets D_{anomalous} \cup D_{new\_anomalies}$.
    \State $D_{enriched} \gets D_{enriched} \cup D_{new\_anomalies}$.
    \State Initialize and train new model $G_i$ on $D_{enriched}$.
    \EndFor
    \State \Return $G_N, D_{anomalous}$.
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
  \caption{Unsupervised Anomaly Mining and Curation (`MineAnomalies`)}\label{alg:anomaly-mining}
  \begin{algorithmic}[1]
    \Require $G_{in}, M, LM\text{-}TAD, Rules$
    \Ensure $D_{new\_anomalies}$

    \State $D_{synthetic} \gets$ Generate $M$ trajectories using $G_{in}$.
    \State Train $LM\text{-}TAD$ on $D_{synthetic}$ using autoregressive language modeling.
    \State $D_{potential} \gets$ Identify outliers in $D_{synthetic}$ using $LM\text{-}TAD$ perplexity scores.
    \State $D_{new\_anomalies} \gets \emptyset$.
    \For{each $traj$ in $D_{potential}$}
    \State $label \gets \text{Categorize}(traj, Rules)$.
    \If{$label \neq \text{None}$}
    \State Add $(traj, label)$ to $D_{new\_anomalies}$.
    \EndIf
    \EndFor
    \State \Return $D_{new\_anomalies}$.
  \end{algorithmic}
\end{algorithm}

\begin{table}[h!]
  \caption{Nomenclature for Algorithms~\ref{alg:iterative-generation} and~\ref{alg:anomaly-mining}}
  \label{tab:nomenclature}
  \centering
  \begin{tabular}{>{\(}l<{\)} p{0.75\textwidth}}
    \hline
    \textbf{Symbol}    & \textbf{Description}                                                                       \\
    \hline
    D_{real}           & A dataset containing real-world, normal trajectories.                                      \\
    D_{synthetic}      & A dataset of trajectories generated by the model.                                          \\
    D_{potential}      & A subset of synthetic trajectories identified as potential anomalies.                      \\
    D_{anomalous}      & A curated dataset of synthetic trajectories labeled as anomalies.                          \\
    D_{enriched}       & The training dataset, augmented with newly curated anomalies.                              \\
    D_{new\_anomalies} & A set of newly discovered and labeled anomalies from an iteration.                         \\
    G_{i}              & The generative model at iteration \(i\).                                                   \\
    G_{in}             & The input generative model for the anomaly mining process.                                 \\
    N                  & The total number of iterative refinement cycles to perform.                                \\
    M                  & The number of synthetic trajectories to generate in each iteration.                        \\
    LM\text{-}TAD      & The autoregressive transformer-based language model used for trajectory anomaly detection. \\
    Rules              & A set of heuristics used to categorize potential anomalies.                                \\
    traj               & A single trajectory data structure.                                                        \\
    label              & The specific anomaly category assigned to a trajectory.                                    \\
    \hline
  \end{tabular}
\end{table}

\subsection{Phase 1: Baseline Synthetic Data Generation}
\label{sec:baseline-generation}

The initial phase focuses on creating a high-fidelity synthetic dataset of normal trajectories, which serves as the foundation for the anomaly mining process.

\begin{description}
  \item[Core Generation Model (\textbf{DiffTraj})] The DiffTraj architecture---a 1D-CNN-based residual network with attention---is adopted for its demonstrated training stability and ability to generate high-quality, realistic trajectories.
  \item[Training on Normal Data] Normal trajectories are identified through a dynamic multi-criteria filtering process applied to each dataset. First, statistical thresholds are computed from the raw trajectory data: origin-destination median times, shortest path distances, and temporal pattern distributions. Then, trajectories are filtered to retain only those with: trip durations within 2 standard deviations of the computed origin-destination medians, distances within reasonable efficiency bounds ($\leq$ 1.5$\times$ computed shortest path), and adherence to the derived typical temporal patterns. The DiffTraj model is then trained solely on this filtered dataset of normal taxi trajectories to capture the underlying patterns of typical urban mobility.
  \item[Output Dataset] This phase produces a synthetic trajectory dataset, \texttt{synthetic\_normal}, which statistically resembles the real normal data but contains no direct copies, thereby ensuring privacy by design.
\end{description}

\subsection{Phase 2: Unsupervised Anomaly Mining and Curation}
\label{sec:anomaly-mining}

This phase uses an unsupervised approach to discover and categorize anomalous patterns within the baseline synthetic data.

\begin{description}
  \item[Unsupervised Anomaly Detection]
    We employ LM-TAD~\cite{mbuyaTrajectoryAnomalyDetection2024}, an autoregressive transformer-based language model for trajectory anomaly detection. Each GPS trajectory is first discretized into a sequence of tokens (e.g., grid cells, staypoints, or activity types). LM-TAD is trained in a self-supervised manner to predict the next location in a trajectory given its historical context, learning the probability distribution over typical movement patterns. For anomaly detection, the model computes the probability of each location in a trajectory conditioned on its preceding locations. The anomaly score for a trajectory is quantified using the perplexity metric, which measures the model's uncertainty in predicting the sequence; higher perplexity indicates greater deviation from normal patterns. Additionally, the surprisal rate can be used to localize specific anomalous locations within a trajectory. LM-TAD supports user- and context-specific anomaly detection by conditioning on user or contextual tokens, and enables efficient online detection by caching attention states. This approach is robust, interpretable, and has demonstrated state-of-the-art performance on both synthetic and real-world GPS trajectory datasets~\cite{mbuyaTrajectoryAnomalyDetection2024}.

    Notably, both DiffTraj~\cite{zhuDiffTrajGeneratingGPS2023} and LM-TAD~\cite{mbuyaTrajectoryAnomalyDetection2024} are designed to work with the same underlying GPS trajectory datasets, including taxi datasets from cities such as Beijing, Chengdu, and Xi'an. While DiffTraj operates directly on continuous GPS coordinates for generation, LM-TAD processes discretized trajectory representations for anomaly detection. This compatibility ensures that the synthetic trajectories generated by DiffTraj can be seamlessly processed by LM-TAD for anomaly scoring, creating a cohesive pipeline from generation to detection without requiring additional data format conversions or significant preprocessing steps.

    The top-ranked anomalies are then passed to the diverse querying and rule-based curation steps for manual review and categorization.

  \item[\textbf{Diverse Querying for Manual Labeling (k-means++ Selection)}] DiffTraj generates synthetic trajectories as sequences of GPS coordinates. For the purpose of diverse querying, we extract feature vectors from these generated GPS trajectories. These features may include trajectory-level statistics (such as total distance, duration, average speed), learned embeddings, or outputs from anomaly detectors. We then apply the k-means++ initialization algorithm (as implemented in \texttt{scikit-learn}'s \texttt{kmeans\_plusplus} function) to these feature vectors to select a subset of $k$ trajectories that are maximally diverse in feature space. The indices returned by k-means++ are used to select the trajectories for manual review and labeling. This diverse querying strategy is based on the SOEL framework~\cite{liDeepAnomalyDetection2023}, which has been shown to maximize labeling efficiency and generalization in semi-supervised anomaly detection settings.

  \item[\textbf{Rule-Based Curation and Categorization}] After the diverse subset of candidate anomalies has been selected via k-means++, we apply rule-based curation and categorization to these trajectories. Each selected trajectory is reviewed (either manually or with automated heuristics) and classified into interpretable anomaly categories using a comprehensive taxonomy of rules based on kinematic, spatial, and behavioral properties.

    Building on the comprehensive taxonomy~\cite{kongMobileTrajectoryAnomaly2024}, we implement a two-category classification system that distinguishes between \textbf{Vehicle-Based Anomalies} (hardware/system related) and \textbf{Behavior-Based Anomalies} (driver/passenger related). This systematic approach enables more precise anomaly characterization and better interpretability for downstream analysis.

    \textbf{Mathematical Formulations for Anomaly Detection:} Following the spatio-temporal trajectory anomaly detection framework~\cite{heEnhancedDBSCANMultiple2020}, we implement the following computational approaches:

    \textbf{Distance-Based Calculations:}
    \begin{align}
      \text{dist}         & = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2} \label{eq:euclidean}           \\
      \text{spatialdist}  & = \frac{1}{e} \times \sum_{i=1}^{e} \text{dist}_i \label{eq:spatial}  \\
      \text{temporaldist} & = \frac{1}{n} \times \sum_{r=1}^{n} \text{span}_r \label{eq:temporal}
    \end{align}

    where $\text{span}_r$ represents the temporal interval between consecutive trajectory points.

    \textbf{Speed Anomaly Detection:} Speed anomalies are detected using~\cite{wangDetectingAnomalousTrajectories2018}:
    \begin{equation}
      v_{anomaly} = \begin{cases}
        1 & \text{if } v_i > \mu_v + 2\sigma_v \text{ or } v_i < \mu_v - 2\sigma_v \\
        0 & \text{otherwise}
      \end{cases}
      \label{eq:speed-anomaly}
    \end{equation}

    where $\mu_v$ and $\sigma_v$ are the mean and standard deviation of speeds for the given route segment.

    \textbf{Route Efficiency Scoring:} Route efficiency is computed as~\cite{chenTemporalContextAwareRoute2021}:
    \begin{equation}
      \text{efficiency} = \frac{\text{shortest\_path\_distance}}{\text{actual\_path\_distance}} \times \frac{\text{expected\_travel\_time}}{\text{actual\_travel\_time}}
      \label{eq:efficiency}
    \end{equation}

    Thresholds for route length and travel time are set following the statistical approach~\cite{wangStatisticalFrameworkTaxi2020,wangDetectingAnomalousTrajectories2018}, where a trajectory is considered anomalous if its characteristics exceed normal trajectory parameters by empirically determined margins.

    \textbf{Specific Anomaly Categories:}
    \begin{itemize}[leftmargin=*]
      \item \textbf{Route Deviation:} Path length $> NL_{value} + L_\rho$, where $NL_{value}$ is the mean normal route length and $L_\rho$ is a margin (e.g., 5 km)~\cite{wangDetectingAnomalousTrajectories2018}.
      \item \textbf{Temporal Delay:} Travel time $> NT_{value} + T_\rho$, where $NT_{value}$ is the mean normal travel time and $T_\rho$ is a margin (e.g., 5 min).
      \item \textbf{Speed Anomalies:} Implementing Equation~\ref{eq:speed-anomaly} to detect both excessive speeding ($> 120$ km/h) and abnormally slow travel ($< 5$ km/h for extended periods)~\cite{heEnhancedDBSCANMultiple2020}.
      \item \textbf{Stop-Duration Anomalies:} Stationary periods $> 15$ min at non-terminal locations, computed using temporal clustering methods for trajectory analysis.
      \item \textbf{Off-Road Driving:} Trajectory points located beyond a reasonable distance ($> 100$ m) from any known road segment, indicating GPS errors or highly unusual vehicle movement, as part of comprehensive trajectory anomaly detection frameworks.
      \item \textbf{U-Turn and Loop Anomalies:} Detection of unnecessary reversals and circular patterns using heading change analysis $|\Delta\theta| > 150^{\circ}$ within short time intervals ($< 2$ min) as implemented in spatio-temporal anomaly detection systems~\cite{heEnhancedDBSCANMultiple2020}.
      \item \textbf{Detour Anomalies:} Routes with efficiency scores (Equation~\ref{eq:efficiency}) below 0.7, indicating significant deviation from optimal paths following established trajectory analysis frameworks.
    \end{itemize}
    This two-step process ensures that manual labeling effort is focused on a diverse and representative set of candidate anomalies, and that each labeled anomaly is further categorized in a systematic and interpretable way, improving both the quality and utility of the curated anomaly set.
  \item[Labeled Anomaly Subsets] This curation process produces labeled anomaly datasets (e.g., \texttt{anomalies\_speeding}, \texttt{anomalies\_off\_road}) that are ready for model retraining.
\end{description}

\subsection{Phase 3: Iterative Refinement and Conditional Generation}
\label{sec:iterative-refinement}

The final phase closes the loop by retraining the diffusion model on the enriched dataset to learn and amplify the discovered anomalous patterns, enabling controlled generation.

\begin{description}
  \item[Enriched Data Retraining] The DiffTraj model is retrained on a dataset that combines the original \texttt{synthetic\_normal} trajectories with the curated, labeled anomalies. The proportion of anomalies is carefully balanced (e.g., 5--10\%) to prevent mode collapse and maintain diversity.
  \item[Iterative Amplification] This process---generation, detection, curation, and retraining---can be repeated multiple times. Each iteration further amplifies and diversifies the model's ability to generate complex and varied anomalies.
  \item[Controlled Anomaly Generation] The refined model supports conditional sampling (e.g., \texttt{difftraj.sample(condition="speeding")}), enabling the targeted generation of specific, high-quality anomalies for downstream tasks.
\end{description}

\subsection{Privacy Protection Implementation}
\label{sec:privacy-implementation}

Building on the privacy protection requirements identified in the literature review (Section~\ref{sec:privacy-review}), this framework implements multiple complementary privacy mechanisms to ensure strong privacy guarantees throughout the synthetic data generation pipeline.

\textbf{Differential Privacy Integration.} The framework integrates differential privacy at the model training level through DP-SGD (Differentially Private Stochastic Gradient Descent) during DiffTraj training. This ensures that individual trajectory influence on the model parameters is bounded, preventing membership inference attacks. The privacy budget $\epsilon$ is carefully allocated across the three phases: baseline generation ($\epsilon_1 = 2.0$), iterative refinement ($\epsilon_2 = 1.0$ per iteration), and final evaluation ($\epsilon_3 = 0.5$).

\textbf{Trajectory-Level Privacy Protection.} Following the trajectory-level privacy unit identified as optimal in the literature review, the framework treats entire trajectories as atomic privacy units rather than individual GPS points. This prevents correlation attacks that exploit temporal dependencies within trajectories. Spatial generalization through grid-based discretization provides additional protection while preserving essential spatial patterns for anomaly detection.

\textbf{Synthetic Data Decoupling.} The core privacy guarantee comes from the generative approach itself: synthetic trajectories are not direct copies or transformations of real data but are generated from learned statistical distributions. This fundamental decoupling provides inherent privacy protection, as demonstrated by the framework's ability to generate novel trajectory patterns that were not present in the original dataset.

\textbf{Attack Resistance Mechanisms.} The framework incorporates specific defenses against membership inference and reconstruction attacks. The iterative refinement process ensures that any individual trajectory's influence diminishes through multiple generation cycles, while the rule-based curation step adds an additional layer of protection by filtering trajectories based on interpretable criteria rather than direct similarity to training data.

\subsection{Model Selection and Justification}
\label{sec:model-selection}

The selection of the DiffTraj model and the iterative, bootstrapping methodology is grounded in a pragmatic assessment of technical advantages and research objectives.

\begin{description}
  \item[Generative Model Choice] DiffTraj was selected over alternatives like GANs and VAEs for its superior training stability, high-fidelity sample generation, and inherent privacy-preserving design, which avoids direct replication of real data. Diffusion models offer significant advantages in training stability by avoiding mode collapse and vanishing gradient challenges that often affect GANs and VAEs, and they generate diverse, high-fidelity samples that accurately represent underlying data distributions~\cite{liuAnomalyDetectionGeneration2025}. In contrast, GAN-based frameworks for synthetic trajectory generation, while effective for privacy preservation, are more prone to instability and mode collapse challenges~\cite{caoGeneratingMobilityTrajectories2021}.
  \item[Rationale for Iterative Approach] The proposed iterative framework was chosen for its key strategic benefits:
    \begin{itemize}[leftmargin=*]
      \item \textbf{No Labeled Data Required:} It bootstraps the anomaly generation process without needing a pre-labeled anomalous dataset, addressing a common bottleneck in anomaly detection research.
      \item \textbf{High Control and Interpretability:} The rule-based curation ensures that generated anomalies correspond to clear, interpretable, and controllable categories. Recent advances in diffusion models highlight the synergistic relationship between anomaly detection and generation, where generation techniques address anomaly data scarcity and detection methods provide feedback to improve generation fidelity and relevance~\cite{liuAnomalyDetectionGeneration2025}.
      \item \textbf{Scalability and Efficiency:} The approach is computationally less intensive than complex latent space manipulation techniques and allows the anomaly dataset to be iteratively expanded and refined. Diffusion models are being actively adapted for scalability and computational efficiency, supporting their use in large-scale synthetic data generation~\cite{liuAnomalyDetectionGeneration2025}.
    \end{itemize}
  \item[Trade-off Analysis] This methodology prioritizes interpretability, control, and implementation feasibility. It serves as a robust foundation, acknowledging that more complex generative techniques like latent space adversarial training are deferred to future work.
\end{description}
