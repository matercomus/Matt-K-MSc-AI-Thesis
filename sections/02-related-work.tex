\section{Related Work}
\label{sec:lit-review}

This section reviews the key research areas relevant to knowledge distillation for trajectory prediction. We examine trajectory prediction and generation methods, synthetic data applications for urban systems, trajectory anomaly detection approaches that learn spatial patterns, knowledge distillation techniques, the architectural foundations in graph neural networks and transformers, and cross-task knowledge transfer methods.

\subsection{Trajectory Prediction and Generation}
\label{sec:lit-traj-pred}

Trajectory prediction and generation have evolved significantly from early LSTM-based approaches to recent large language model frameworks. Early methods~\cite{liang2018memory} employed memory-augmented neural networks to capture trajectory patterns, enabling sophisticated pattern learning for trajectory modeling. Deep generative approaches using variational autoencoders~\cite{liuOnlineAnomalousTrajectory2020} demonstrated the potential for modeling trajectory uncertainty through latent representations.

Recent advances leverage diffusion models~\cite{chuSimulatingHumanMobility2024} for trajectory generation, demonstrating zero-shot prediction capabilities by modeling generation as an uncertainty-reducing process. The T

rajGPT framework~\cite{hsuTrajGPTControlledSynthetic2024} introduced controlled generation using transformer-based spatiotemporal modeling, achieving significant improvements in temporal accuracy while maintaining high spatial precision. PathGen-LLM~\cite{liPathGenLLMLargeLanguage} applies large language models to dynamic path generation in transportation networks, directly addressing the challenge of generalization to unseen origin-destination pairs through self-supervised pre-training on historical paths.

The evolution from traditional GAN-based methods~\cite{raoLSTMTrajGANDeepLearning2020} to recent transformer and diffusion approaches highlights a persistent challenge: balancing route completion accuracy with computational efficiency. Comparative studies~\cite{zhangEndtoendTrajectoryGeneration2025} demonstrate that while language model approaches excel at capturing complex sequential patterns, they face computational overhead that limits real-time deployment. The GTG framework~\cite{wangGTGGeneralizableTrajectory2025} emphasizes cross-city generalizability, a critical requirement for practical traffic management systems.

A fundamental limitation emerges across these approaches: vanilla prediction models often achieve only 12-18\% route completion rates on complex urban networks, severely limiting their utility for operational traffic management and digital twin applications. This motivates the need for methods that can dramatically improve completion rates while maintaining inference speed suitable for real-time deployment.

\subsection{Synthetic Trajectory Generation for Urban Applications}
\label{sec:lit-synthetic-urban}

High-fidelity synthetic trajectory generation serves critical functions in urban planning, traffic simulation, and digital twin development beyond traditional privacy considerations. SynMob~\cite{zhuSynMobCreatingHighFidelity} employs diffusion models to generate synthetic GPS trajectories that retain geo-distribution and statistical properties of real data, explicitly emphasizing utility for urban planning, transportation planning, and policy decisions rather than privacy preservation. The framework demonstrates that synthetic data can support infrastructure planning and traffic analysis without requiring access to individual real trajectories.

Foundation model approaches~\cite{maLearningUniversalHuman2025} demonstrate cross-domain data fusion for universal mobility pattern learning, validating utility through large-scale traffic simulations. This work integrates multi-modal urban data (geographical, mobility, socio-demographic, traffic) to create semantically enriched trajectory datasets suitable for agent-based simulation and urban digital twin systems. The emphasis on domain transfer techniques enables knowledge sharing across cities and transportation modes, directly supporting the scalability requirements of operational traffic management.

TrajGDM~\cite{chuSimulatingHumanMobility2024} models trajectory generation as capturing universal mobility patterns through step-by-step uncertainty reduction, demonstrating applications in trajectory prediction and reconstruction. The framework's ability to generate diverse, realistic trajectories makes it valuable for training other models, populating simulation environments, and testing traffic management algorithms under various scenarios.

These synthetic generation methods address practical challenges in traffic management: generating training data for prediction models, creating test scenarios for infrastructure planning, populating agent-based simulations with realistic behavior patterns, and providing data for digital twin systems that mirror real urban mobility without exposing individual trajectories. The shift from privacy-centric to utility-centric synthetic generation better aligns with stakeholder needs in transportation planning and policy development.

\subsection{Trajectory Anomaly Detection and Spatial Learning}
\label{sec:lit-anomaly-spatial}

Trajectory anomaly detection methods learn rich spatial representations of normal trajectory patterns, providing a foundation for understanding typical urban mobility behaviors. Deep generative approaches~\cite{liuOnlineAnomalousTrajectory2020} use variational autoencoders for sequence modeling, learning to distinguish between normal and anomalous movement patterns through reconstruction quality. LSTM autoencoder architectures incorporate attention mechanisms to focus on salient spatiotemporal features, effectively capturing sequential dependencies in trajectory data.

Spatiotemporal methods~\cite{heSpatiotemporalTrajectoryAnomaly2022} identify anomalies through common sub-sequence analysis, while spatial-feature approaches combine multiple dimensions of trajectory data for robust outlier detection in large-scale systems. Comprehensive taxonomies~\cite{kongMobileTrajectoryAnomaly2024} categorize anomaly detection methods, highlighting the evolution from statistical approaches to deep learning frameworks. Real-time detection systems~\cite{huRealtimeTaxiSpatial2024} employ Seq2Seq models to predict expected trajectories, identifying deviations through spatial consistency measures. GRU-based approaches~\cite{tangLowcostHighperformanceAbnormal2024} demonstrate cost-effective anomaly detection through deep spatiotemporal sequence analysis.

The key insight for trajectory prediction is that models designed to detect anomalies must first learn comprehensive representations of normal trajectory patterns. These models encode spatial relationships between locations, typical movement sequences, and context-dependent routing behaviors. The LM-TAD framework represents anomaly detection as a language modeling task, learning probability distributions over trajectory tokens through transformer architectures. This spatial understanding—knowing which routes are typical and which are unusual—directly translates to prediction capability.

However, transformer-based anomaly detection models incur significant computational cost (~3.4ms per trajectory for LM-TAD) compared to fast prediction models (~0.1ms for vanilla HOSER), creating a deployment challenge for real-time traffic management systems. This motivates transferring the spatial knowledge learned during anomaly detection model training to faster prediction models, enabling operational deployment without inference-time overhead.

\subsection{Knowledge Distillation and Model Compression}
\label{sec:lit-distill}

Knowledge distillation~\cite{hintonDistillingKnowledgeNeural2015} enables fast student models to learn from slower teacher models through soft targets and temperature scaling during training. The foundational work demonstrates that student networks can achieve comparable accuracy to larger teachers by learning from the teacher's softened output distributions rather than hard labels alone. Temperature scaling controls the smoothness of these distributions, providing richer training signals that capture relationships between classes beyond simple classification boundaries.

Knowledge distillation has proven effective for model compression across computer vision and natural language processing domains, consistently demonstrating that smaller models can capture essential patterns learned by larger counterparts. The technique is particularly valuable when deployment constraints require fast inference but training resources allow for sophisticated teacher models. By distilling at training time only, the approach imposes no inference overhead, making it ideal for real-time applications like traffic management.

Applying knowledge distillation to trajectory prediction represents a novel cross-task application. Rather than compressing a model for the same task (e.g., a smaller prediction model learning from a larger prediction model), this work transfers spatial understanding from a trajectory anomaly detection model (LM-TAD) to a trajectory prediction model (HOSER). The key insight is that anomaly detection models learn comprehensive representations of normal trajectory patterns that are directly applicable to prediction tasks. This cross-task distillation enables dramatic improvements in route completion (from 12-18\% to 85-89\%) while maintaining fast inference suitable for operational deployment.

\subsection{Graph Neural Networks for Road Networks}
\label{sec:lit-gnn}

Graph neural networks naturally model road network topology by representing locations as nodes and connections as edges. The Graph Convolutional Network (GCN)~\cite{kipfSemisupervisedClassificationGraph2017} provides foundational spectral methods for learning on graph-structured data, enabling aggregation of information from neighboring nodes through localized filters. HOSER employs GCN for zone-level aggregation, capturing relationships between geographic regions in the road network.

Graph Attention Networks (GAT)~\cite{velickovicGraphAttentionNetworks2018} extend this foundation by learning adaptive attention weights for different neighbors, allowing models to focus on the most relevant connections. HOSER's road-level encoding uses GATv2 to weight connections between individual road segments, enabling fine-grained spatial reasoning about likely transitions.

The multi-level hierarchy in HOSER—combining GAT for road-level features with GCN for zone-level aggregation—captures spatial structure at different scales. This architectural choice reflects the reality that urban navigation involves both local decisions (which turn to take at an intersection) and regional planning (which neighborhoods to traverse). GNN architectures' ability to encode graph topology makes them well-suited for transportation applications where spatial connectivity fundamentally constrains movement patterns.

\subsection{Transformer Architecture for Sequential Modeling}
\label{sec:lit-transformer}

Transformers~\cite{vaswaniAttentionAllYou2023} revolutionized sequential modeling through self-attention mechanisms and causal masking for autoregressive prediction. Self-attention enables modeling long-range dependencies in sequences by directly computing relationships between all positions, avoiding the sequential bottleneck of recurrent architectures. Causal masking ensures that predictions at each position depend only on previous elements, crucial for trajectory modeling where future locations cannot influence past decisions.

LM-TAD employs transformer architecture for trajectory anomaly detection, treating trajectories as sequences of tokens similar to natural language. The self-attention mechanism learns which prior locations in a trajectory are most relevant for predicting the next location, capturing both local movement patterns and global route structure. Recent applications~\cite{liPathGenLLMLargeLanguage} demonstrate that large language model techniques can effectively handle dynamic path generation in transportation networks, learning spatial-temporal patterns through self-supervised pre-training on historical trajectory corpora.

The computational cost of transformers—particularly the quadratic complexity of self-attention with sequence length—creates deployment challenges for real-time traffic management. While transformers excel at learning complex sequential patterns during training, their inference cost limits large-scale operational use. This trade-off between pattern learning capability and deployment efficiency motivates knowledge distillation approaches that transfer transformer-learned knowledge to faster architectures.

\subsection{Cross-Task Knowledge Transfer}
\label{sec:lit-transfer}

Cross-task knowledge transfer enables models trained for one objective to improve performance on related but distinct tasks. Foundation models for mobility~\cite{maLearningUniversalHuman2025} demonstrate domain transfer techniques that enable knowledge sharing across different cities, data modalities, and transportation contexts. These models learn universal patterns through multi-modal data integration, then adapt to specific tasks through fine-tuning or zero-shot transfer.

Transferring knowledge from anomaly detection to trajectory prediction represents a novel cross-task application where the source and target tasks have fundamentally different objectives. Anomaly detection learns what constitutes normal behavior to identify deviations, while prediction learns to forecast future locations given past observations. Despite this difference, both tasks require understanding typical movement patterns, spatial constraints, and context-dependent routing behaviors.

The challenge in cross-task distillation lies in bridging different model architectures, vocabularies, and output spaces. LM-TAD operates on grid cell tokens (51,663 vocabulary) while HOSER predicts road segment IDs (40,060 vocabulary), requiring careful mapping between representations. Success depends on identifying shared underlying patterns—in this case, knowledge of normal trajectory sequences—that transfer across task boundaries. This transfer learning paradigm directly addresses stakeholder needs for fast, accurate trajectory prediction by leveraging sophisticated models during training while maintaining deployment efficiency.
