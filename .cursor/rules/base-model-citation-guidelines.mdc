---
globs: sections/*.tex
description: Guidelines for citing base models without over-explaining their details
---

# Base Model Citation Guidelines

## Core Principle
**Your thesis should focus on YOUR novel contribution.** Base models (HOSER, LM-TAD, etc.) should be briefly described with citations to their original papers, not exhaustively documented.

## What to Include vs What to Cite

### ✅ Include in Your Thesis
- **Purpose**: What the model does and why you use it
- **Interface details**: Vocabulary sizes, input/output formats needed for YOUR work
- **Performance metrics**: Inference speeds relevant to YOUR comparison
- **Integration points**: How it connects to your contribution

### ❌ Cite to Original Paper
- Layer counts, embedding dimensions, attention heads
- Internal architecture diagrams (unless modifying them)
- Training procedures for the base model
- Hyperparameters for base model training
- Detailed ablation studies from original paper
- File format specifications (unless YOU modify them)

## Template Patterns

### Base Model Specification
```latex
% ❌ TOO DETAILED
\textbf{Teacher (LM-TAD):} A transformer with 6 layers, 512-dimensional 
embeddings, 8 attention heads, causal masking, and learned positional 
encodings. The model uses layer normalization and dropout rate of 0.1...

% ✅ APPROPRIATE
\textbf{Teacher (LM-TAD)~\cite{mbuyaTrajectoryAnomalyDetection2024}:} 
A pre-trained transformer for trajectory anomaly detection that models 
trajectories as sequences of grid cell tokens. Input vocabulary size 
$|\mathcal{Z}| = 51{,}663$ for Beijing. Inference speed: $\sim$430 ms/batch 
(frozen during distillation). Architecture details in the original paper.
```

### Data Format Description
```latex
% ❌ TOO DETAILED
The road network is defined by roadmap.geo containing road_id (unique integer 
identifier 0 to |V|-1), geometry (coordinate sequence defining road shape), 
highway (road type: primary, secondary, residential, etc.), length (physical 
length in meters), lanes (number of traffic lanes), maxspeed (speed limit)...

% ✅ APPROPRIATE
We use the HOSER dataset format~\cite{caoHolisticSemanticRepresentation2025}, 
which represents trajectories as sequences of map-matched road segment IDs with 
timestamps and explicit origin-destination pairs. The road network topology 
enables candidate generation for spatial pruning during prediction.
```

### Preprocessing Steps
```latex
% ❌ TOO DETAILED
We partition the road network into Z=300 zones using the KaHIP graph 
partitioning library, which minimizes edge cuts while balancing zone sizes. 
The algorithm uses multilevel graph partitioning with initial coarsening, 
initial partitioning, and local improvement phases...

% ✅ APPROPRIATE
The student model operates on hierarchical zones as specified in the original 
HOSER paper~\cite{caoHolisticSemanticRepresentation2025}. Zone partitioning 
follows procedures detailed in Section~\ref{sec:preprocessing-pipeline}.
```

## Citation Strategy

### When Base Model is Central to Your Work
Even if a base model is essential to your contribution, keep descriptions brief:

1. **First mention**: Full name + brief description + citation
   ```latex
   We use HOSER~\cite{caoHolisticSemanticRepresentation2025}, a hierarchical 
   graph-aware trajectory predictor, as our student model.
   ```

2. **Subsequent mentions**: Short name only
   ```latex
   The HOSER student operates on road sequences...
   HOSER's candidate pruning reduces...
   ```

3. **Architecture details needed**: Cite specifically
   ```latex
   HOSER uses zone embeddings to capture regional patterns (see 
   \cite{caoHolisticSemanticRepresentation2025} for architecture details).
   ```

### When Comparing Multiple Models
Focus on distinguishing characteristics, not exhaustive descriptions:

```latex
While LM-TAD~\cite{mbuyaTrajectoryAnomalyDetection2024} uses grid-based 
tokenization for anomaly detection, HOSER~\cite{caoHolisticSemanticRepresentation2025} 
operates directly on road segments for prediction. This vocabulary mismatch 
necessitates the alignment mechanism we propose in Section~\ref{sec:vocab-align}.
```

## Red Flags (Indicates Over-Explanation)

Watch for these patterns in your writing:

- **Listing layers**: "The model has a 2-layer GCN followed by..."
- **Describing training**: "The base model was trained with Adam optimizer..."
- **Detailing file schemas**: "Each entry contains field X, field Y, field Z..."
- **Explaining algorithms**: Step-by-step description of base model's algorithm
- **Showing their diagrams**: Unless you're modifying their architecture

## Decision Tree

```
Is this information about a base model (not YOUR contribution)?
├─ YES → Is it needed to understand YOUR work?
│   ├─ YES → Is it in the original paper?
│   │   ├─ YES → Brief mention + citation
│   │   └─ NO → Include if truly necessary
│   └─ NO → Remove it entirely
└─ NO (it's YOUR contribution) → Include full details
```

## Examples from This Thesis

### Our Novel Contribution (Full Detail)
- Vocabulary alignment mechanism (Algorithm + equations)
- Temperature-scaled distillation (Full formulation)
- Training pipeline integration (Complete algorithm)
- Hyperparameter optimization results (All details)

### Base Models (Brief + Cite)
- HOSER architecture → Cite Cao et al. 2025
- LM-TAD architecture → Cite Mbuya et al. 2024
- KaHIP partitioning → Cite Sanders 2011
- Optuna framework → Cite Akiba et al. 2019

## Quick Check
Before writing about a base model, ask:
1. "Would I cite this if asked where this information comes from?" → If yes, cite instead
2. "Does the reader need this to understand MY contribution?" → If no, remove
3. "Am I documenting their work or explaining mine?" → Should be explaining yours
